---
title: "Testing"
layout: default
permalink: /page_test_suite.html
---
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">DynamoRIO
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Testing </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="autotoc_md266"></a>
Automated Test Machines</h1>
<h2><a class="anchor" id="autotoc_md267"></a>
Continuous Integration (CI) via Github Actions</h2>
<p>We have <a href="https://docs.github.com/en/free-pro-team@latest/actions">Github Actions</a> set up to run our short test suite (the same as the pre-commit suite) for every push to the master branch and for every pull request, for 32-bit and 64-bit x86 on Linux and Windows, for 64-bit Mac, and for AArch64 on Linux. ARM (32-bit) and Android builds are performed but no tests are run at this point. The Github Actions CI can also be triggered manually, for master or any other branch, on the <a href="https://github.com/DynamoRIO/dynamorio/actions">DynamoRIO Github Actions page</a>.</p>
<p>An email is sent whenever there is a (non-flaky-test) failure. If your commit causes a failure on a merge to master, please forward this email to the dynamorio-devs mailing list explaining the failure and whether you will be reverting your commit (which you should do unless you have a trivial fix ready immediately). If any tests become flaky, please contribute to addressing them to keep our continuous integration testing clean and green.</p>
<p>The Github Actions configuration is specified in the workflow files in <a href="https://github.com/DynamoRIO/dynamorio/blob/master/.github/workflows">.github/workflows</a>.</p>
<p>We have a default test suite verbosity of <code>ctest -VV</code> in <code>suite/runsuite_wrapper.pl</code> (<code>ctest --output-on-failure -VV -S</code>) which shows build warnings and failing test output. The Actions integrated output viewer is slow; it is often better to use the right-hand three-dot menu to select <code>View raw logs</code> or <code>Download log archive</code>.</p>
<h2><a class="anchor" id="autotoc_md268"></a>
CI Job Auto-Cancellation</h2>
<p>We have configured the CI such that if a new commit is pushed to a pull request before the prior CI jobs have finished running, the prior jobs will be cancelled (with an email sent for each cancellation). This is to conserve CI resources under the assumption that the old results are no longer needed.</p>
<h2><a class="anchor" id="autotoc_md269"></a>
CI for AArch64 &amp; AArch32</h2>
<p>We use Jenkins for pre- and postcommit testing on AArch64. <a href="http://jenkins.dynamorio.org:8080/">Jenkins</a> is set up to run our short test suite (the same as the pre-commit suite) for every push to the master branch and for every pull request. We also run a subset of the test suite under QEMU emulation on both AArch32 and AArch64, but not all tests are able to run that way.</p>
<h2><a class="anchor" id="autotoc_md270"></a>
CI Tree Closures</h2>
<p>If the CI on master turns red, the tree is "closed": meaning that there should be no commits to the repository unrelated to fixing the problem until it is green again.</p>
<h2><a class="anchor" id="autotoc_md271"></a>
Trybots</h2>
<p>Our CI setups provide "trybot" functionality for nearly every platform via pull request testing. To test a change on platforms you don't have locally, or test whether your change will pass the CI, you can create a pull request. The CI will then automatically run the test suite on your change.</p>
<h2><a class="anchor" id="autotoc_md272"></a>
Debugging Tests on Github Actions Runner</h2>
<p>Test failures that happen only on Github Actions and are not reproducible locally can be hard to debug. Fortunately, there's a way to SSH into a Github Actions runner to debug the test. This can be done using <code>tmate</code>: <a href="https://github.com/marketplace/actions/debugging-with-tmate">https://github.com/marketplace/actions/debugging-with-tmate</a>. Follow instructions on the page to make a temporary change to the Github Actions workflow config in your branch, and use the link output by <code>tmate</code> to ssh into the runner. You can install <code>gdb</code> if needed on the runner. <code>tmate</code> also allows web shell access; note that you may need to press <code>q</code> one time if the web page doesn't show anything.</p>
<h1><a class="anchor" id="autotoc_md273"></a>
Regression Test Suite</h1>
<p>The black box test suite for DynamoRIO resides in the suite/ directory. The tests are applications that we execute under control of DynamoRIO to ensure we're covering corner cases.</p>
<h2><a class="anchor" id="autotoc_md274"></a>
Test Organization</h2>
<p>The tests in suite/tests/ are divided into different directories according to type of test:</p>
<ul>
<li>client-interface/ = tests of the regular client API</li>
<li>api/ = tests using the IR to test decoding and encoding, and a test of the start/stop interface</li>
<li>common/ = cross-platform basic test applications</li>
<li>linux/ = Linux-specific tests</li>
<li>pthreads/ = more Linux tests, using pthread</li>
<li>win32/ = Windows-specific tests</li>
<li>runall/ = Windows-specific tests using AppInit or follow-children injection</li>
</ul>
<p>There are also tests that are less directly focused on the API of this open-source project, but that are still useful as they contain some crazy behavior that is good to test:</p>
<ul>
<li>security-common/ = tests of security policies</li>
<li>security-linux/ = Linux-specific tests of security policies</li>
<li>security-win32/ = Windows-specific tests of security policies</li>
</ul>
<h2><a class="anchor" id="autotoc_md275"></a>
Building and Running Tests</h2>
<p>CMake is used to build the tests. They are not built by default. To enable them, turn on the BUILD_TESTS CMake variable. For example: </p><div class="fragment"><div class="line">cmake -DBUILD_TESTS=ON ../dynamorio</div>
</div><!-- fragment --><p>CTest is used to run the tests with various runtime options. Each test is named to indicate the runtime options and the executable. The options are first, separate by commas, with a pipe delimiting the end of the options. The executable has a dot instead of a slash. Here are some examples:</p>
<div class="fragment"><div class="line">code_api|security-common.decode-bad-stack</div>
<div class="line">code_api,disable_traces|client.events</div>
</div><!-- fragment --><p>Note that CTest versions prior to 2.8 truncate the test names to 30 characters, so the second example above may show up as:</p>
<div class="fragment"><div class="line">code_api,disable_traces|client</div>
</div><!-- fragment --><p>From a build directory that was built with BUILD_TESTS you can run the set of tests for that build with the <code>test</code> Makefile target. You need to build first with a plain <code>make</code> command as the <code>test</code> target does not check for that.</p>
<div class="fragment"><div class="line">make -j6</div>
<div class="line">make test</div>
</div><!-- fragment --><p>You can also invoke <code>ctest</code> directly, which gives greater control over which subsets of the tests are run. Use <code>ctest -N</code> to see the list of tests and which number is assigned to each. Then you can use <code>ctest -I x,y</code> to run all tests from number x to number y, and the -V parameter to display the command line and the output of the test. For example:</p>
<div class="fragment"><div class="line">ctest -V -I 49,49</div>
</div><!-- fragment --><p>You can also specify tests using inclusion and exclusion regular expressions. For example:</p>
<div class="fragment"><div class="line">ctest -R <span class="stringliteral">&#39;strace|signal&#39;</span></div>
</div><!-- fragment --><p>will run all tests with the string "strace" or the string "signal" in their names, while</p>
<div class="fragment"><div class="line">ctest -E security-common</div>
</div><!-- fragment --><p>will run all tests except those with security-common in their names.</p>
<p>If you are using CTest version 2.8 or later, you can run tests in parallel by passing -jN to <code>ctest</code> on the command line:</p>
<div class="fragment"><div class="line">ctest -j5</div>
</div><!-- fragment --><p>As an alternative to using -V to display the test command line and output during executing, CTest stores that information (even when not run with -V) in the <code>Testing/Temporary/LastTest.log</code> file in the build directory.</p>
<h2><a class="anchor" id="autotoc_md276"></a>
Testing AArchXX</h2>
<p>Currently we have access to the following machines for contributors to do testing on actual AArchXX hardware (please contact <code>@AssadHashmi</code> if you want access):</p>
<ul>
<li>one AArch64 ThunderX1, hosted on packet.net</li>
</ul>
<p>We also have support for running tests under QEMU emulation. This is automatically set up if <code>qemu-user</code> is installed:</p>
<div class="fragment"><div class="line">$ sudo apt-get install qemu-user qemu-user-binfmt</div>
</div><!-- fragment --><p>For instructions on how to manually run under QEMU, see <a class="el" href="page_deploy.html#qemu_deploy">Running Under QEMU</a>.</p>
<h2><a class="anchor" id="autotoc_md277"></a>
Test Output</h2>
<p>Each test produces output to stderr and/or stdout that is diffed against an expected output. There are three primary ways we calculate the expected output. The first is from a literal file with an .expect extension: e.g., suite/tests/common/segfault.expect.</p>
<p>The second is from a .template file that is evaluated with respect to the current build and runtime option parameters to produce an .expect file for literal diffing: e.g., suite/tests/common/decode.template. The C preprocessor is used to convert the .template file to a literal string for matching. Runtime options are converted to compiler definitions and added to those set for the build when running the preprocessor. This allows the test output to be conditional on the build defines and runtime parameters.</p>
<p>The third is a .templatex file, which is like a .template file but is also evaluated as a regular expression instead of a literal string after passing through the pre-processor.</p>
<p>All three of those options use the CTest property PASS_REGULAR_EXPRESSION (with regular expression characters escaped when not using .templatex). That property has a size limit. There are other methods of comparing output. One is to use programmatic comparisons inside the test. Another is to use our script runcmp.cmake which has no size limit.</p>
<h2><a class="anchor" id="autotoc_md278"></a>
Pre-Commit Test Suite</h2>
<p>The suite/runsuite.cmake script is used to execute a series of builds and test runs. Running <code>make test</code> in a single build directory is not sufficient to test all of the configurations that we support. The test suite requires a development environment that is capable of compiling for both 64-bit and 32-bit (see [How To Build](How-To-Build) for instructions on setting up Ubuntu appropriately).</p>
<p>We have two different suites: the short suite, which is required to be run prior to committing code changes (see CommitCriteria), and the long suite, which is meant to be run as a nightly test suite on different platforms (see <a href="Test-Suite#nightly-suite">Nightly Suite</a>). The suite/tests/CMakeLists.txt file controls which runs are executed for each build, while suite/runsuite.cmake lists the builds. The long suite can be executed by using the suite/runsuite_long.cmake wrapper script.</p>
<p>On Windows, runsuite.cmake assumes that the environment variables are set up for building, just like when configuring a single build directory. The script will change from 32-bit to 64-bit and vice versa when necessary; to do so, it assumes the typical Visual Studio layout of 64-bit subdirectories.</p>
<p>The runsuite.cmake script is meant to be executed from an empty directory. It creates a subdirectory for each build in the suite. Use <code>ctest -S</code> to execute the script. Here is an example:</p>
<div class="fragment"><div class="line">mkdir ../build_suite</div>
<div class="line">cd ../build_suite</div>
<div class="line">ctest -S ../dynamorio/suite/runsuite.cmake</div>
</div><!-- fragment --><p>We recommend using Ninja, in which case pass the use_ninja parameter:</p>
<div class="fragment"><div class="line">mkdir ../build_suite</div>
<div class="line">cd ../build_suite</div>
<div class="line">ctest -S ../dynamorio/suite/runsuite.cmake,use_ninja</div>
</div><!-- fragment --><p>You can pass -V (or -VV for more output) to ctest to see the results as the test suite runs. Note that it is normal to have ctest output strings such as "No tests were
found!!!" as we have builds for which we run no tests (particularly in the short suite). It is also expected to have an error at the end of the suite (if run with -V):</p>
<div class="fragment"><div class="line">CMake Error: Some required settings in the configuration file were missing:</div>
<div class="line">CTEST_SOURCE_DIRECTORY = E:/derek/dr/suite/..</div>
<div class="line">CTEST_BINARY_DIRECTORY = (Null)</div>
<div class="line">CTEST_COMMAND = c:/PROGRA~2/CMAKE2~1.6/bin/ctest.exe</div>
</div><!-- fragment --><p>This warning is an artifact of how CTest assumes we've set things up and can be ignored.</p>
<p>At the end of the suite a file called results.txt will be created and displayed. It shows configure failures, build failures, and test failures. It also looks for DynamoRIO crashes, asserts, and curiosities and displays those.</p>
<p>For details on configure, build, or test failures, look in the Testing/Temporary/Last* log files inside the appropriate build subdirectory of the top-level suite directory. For example:</p>
<div class="fragment"><div class="line">cd ~/dr/build_suite</div>
<div class="line">less build_debug-<span class="keyword">internal</span>-32/Testing/Temporary/LastTest_20150708-1437.log</div>
</div><!-- fragment --><p>Note that the build directories are quite large. For a short suite on Linux they occupy about 600MB altogether.</p>
<h2><a class="anchor" id="autotoc_md279"></a>
Cross-Compilation and Android Testing</h2>
<p>The test suite includes cross-compilation tests to ensure that the ARM and Android builds are not broken. If a cross-compiler is not found on the PATH, these builds will fail, but they are considered optional, so the whole suite will not be considered a failure. However, we recommend installing the cross-compilers and placing them on your PATH for more thorough testing.</p>
<p>If you have an Android device set up for access through the <code>adb shell</code> utility, the Android build is capable of automatically copying binaries to the device and running tests. If both the Android cross-compiler and <code>adb</code> are on your PATH, and <code>adb status</code> indicates an attached device, the tests will be run.</p>
<h2><a class="anchor" id="autotoc_md280"></a>
Pre-Commit Test Suite Over Ssh</h2>
<p>The runsuite_ssh.cmake script can be used to launch the pre-commit test suite on a remote machine over ssh. Remote Windows machines are supported when using cygwin sshd on the remote machine. Both rsync and ssh must be installed on the local and remote machines, and RSA-key passwordless authentication is recommended.</p>
<div class="fragment"><div class="line">cd /my/checkout &amp;&amp; cmake -DHOST=dr-ubuntu -P suite/runsuite_ssh.cmake</div>
</div><!-- fragment --><p>For a remote Windows machine, cygpath must be on the path, and the REMOTE_WINDOWS variable must be set to properly convert paths:</p>
<div class="fragment"><div class="line">cmake -DHOST=mylaptop -DUSER=derek -DREMOTE_WINDOWS=ON -P /my/checkout/suite/runsuite_ssh.cmake</div>
</div><!-- fragment --><p>The comments at the top of runsuite_ssh.cmake describe additional options.</p>
<h2><a class="anchor" id="autotoc_md281"></a>
Test Failures</h2>
<p>Unfortunately our test suite is not as clean as it could be. Some tests can be flaky and while they pass on the machines of the existing developers and on our automated test machines, they may fail occasionally on a new machine. Please search the issue tracker before filing a new issue to see if a test failure has already been seen once before. We welcome contributions to fix flaky tests.</p>
<h2><a class="anchor" id="autotoc_md282"></a>
Missing Tests</h2>
<p>Some features that were tested in our pre-cmake infrastructure have not been ported to cmake. We welcome contributions in this area:</p>
<ul>
<li>Issue 120: port runall test infrastructure to cmake. This is needed to properly run all tests that use notepad or calc on Windows (these tests are currently disabled so they do not show up as failures):<ul>
<li>client-interface/cbr2</li>
<li>client-interface/cbr</li>
<li>client-interface/custom_traces</li>
<li>client-interface/decode-bb</li>
<li>client-interface/nudge_test</li>
<li>client-interface/pc-check</li>
<li>all runall/ tests</li>
</ul>
</li>
<li>Issue 16: tests not building or updated properly for X64. Such tests include (these tests are currently disabled so they do not show up as failures):</li>
<li>Issue 125: re-enable tests: linux.vfork, linux.vfork-fib, win32.debugger, security-common.selfmod-big</li>
<li>Issue 1670: port rest of test suite to ARM</li>
</ul>
<p>Any effort put into cleaning up the test failures and moving toward zero expected failures is greatly appreciated.</p>
<h1><a class="anchor" id="autotoc_md283"></a>
Adding New Tests</h1>
<p>In order to add any tests to the regression suite, first choose the sub directory in which you are going to add your tests (see <a href="Test-Suite#test-organization">Test Organization</a>). Pick a test from that directory based on which you are going to model yours and study it well, especially the .template file associated with that test case, because that determines what the expected output will be for this particular test in different runs of the regression suite where the options will be different.</p>
<p>Make sure that your test case has the statement <code>INIT();</code> in it; this is necessary to catch unhandled exceptions on Windows. Lack of adding this line can cause the regression suite to break. Also, use print() rather than printf() because the former flushes the output (a problem on cygwin). Include <code>tools.h</code> in your test.</p>
<p>Once the basic test has been set up and tested, following the process for checking in code at CommitCriteria to add your test. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- HTML footer for doxygen 1.8.17-->
<!-- start footer part -->
<!--BEGIN GENERATE_TREEVIEW-->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer" style="float:none;text-align:center"><img border=0 src="favicon.png"> &nbsp;  DynamoRIO version 9.0.1 --- Mon Feb 14 2022 19:04:14 &nbsp; <img border=0 src="favicon.png">
</small></address>
